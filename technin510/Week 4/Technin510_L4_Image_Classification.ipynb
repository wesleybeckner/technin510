{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Technin510_L4_Image_Classification.ipynb","provenance":[{"file_id":"1xxG_BAYb69MpsaTqvlsAzU7NfqVSrGtQ","timestamp":1600962194357},{"file_id":"1FsYnrcBAuvHM7lRzcYxnIfJ18A1BsoKv","timestamp":1600960182974}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NseBwf7G1t9P"},"source":["# LAB 4: Image Classification\n","\n","## Step 1: Create project/folder and download data\n","\n","Download [lab-4.zip](https://drive.google.com/file/d/1vjt-_R1YnpIkxoytykU_ZZ5CLNP7fVgi/view?usp=sharing) and unzip it. Place the `train/` and `test/` folders into `lab-4/` folder you create on your Google drive. These folders include images of five 'symbol' cards as seen from a small robot's camera. Also copy `lab4.ipynb` into the `lab-4/`."]},{"cell_type":"markdown","metadata":{"id":"mqgTPZYE3AgX"},"source":["## Step 2: Implement feature extraction\n","\n","Below is a skeleton code for an image classification class called ImageClassifier as well as code for creating, training, and testing a classifier with the provided data sets. The three functions you will need to implement are indicated with comments in the code.\n","\n","The first one of these is `extract_image_features` which should return a Numpy array that contains the features that represent the image. Before extracting any features, you should apply Gaussian blurring to your images to get rid of random sensor noice that is common in many lower cost cameras. For this, look into the filters module of scikit-image. Then explore at least two different types of features provided in the feature module of scikit-image. Inspect the size of the feature vectors generated by different methods and what the features look like for different images from the training or testing set. \n","\n","You will not yet get a good sense of how well each feature performs in allowing the classifiers to discriminate between different images. Hence, keep your code for extracting different features around until you explore classification performance in the next step. You can do that by duplicating the function with different names for different features."]},{"cell_type":"code","metadata":{"id":"S99lms1i1BPE"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","\n","from sklearn import svm, metrics\n","from skimage import io, feature, filters, exposure, color, exposure\n","\n","from sklearn.externals import joblib\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","class ImageClassifier:\n","    \n","    def __init__(self):\n","        self.classifier = None\n","        self.folder = '/content/drive/My Drive/TECHIN 510 Programming For Digital And Physical User Interfaces/Lab 4/lab4-data/'\n","\n","    def imread_convert(self, f):\n","        return io.imread(f).astype(np.uint8)\n","\n","    def save_classifier(self):\n","        joblib.dump(self.classifier, self.folder + 'classifier.joblib')\n","\n","    def load_data_from_folder(self, dir):\n","        # read all images into an image collection\n","        ic = io.ImageCollection(self.folder + dir + '*.bmp',\n","                                load_func=self.imread_convert)\n","\n","        # create one large array of image data\n","        data = io.concatenate_images(ic)\n","        \n","        # extract labels from image names\n","        labels = np.array(ic.files)\n","        for i, f in enumerate(labels):\n","            m = re.search('_', f)\n","            labels[i] = (f[len(dir):m.start()]).split('/')[-1]\n","        \n","        return(data,labels)\n","\n","    def extract_image_features(self, data, feature):\n","        ########################################################################\n","        ############################ YOUR CODE HERE ############################\n","        ########################################################################\n","\n","        # apply gaussian filter\n","        \n","        # derive features from filtered data, return a vector\n","        \n","        pass # delete this line"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fPG2wS285ytL"},"source":["Here is the code for creating an instance of the class, loading the data, and extracting the features."]},{"cell_type":"code","metadata":{"id":"FQumlfXtt5hr"},"source":["img_clf = ImageClassifier()\n","\n","# load images\n","print('Loading training set...')\n","(train_raw, train_labels) = img_clf.load_data_from_folder('train/')\n","print('Loading testing set...')\n","(test_raw, test_labels) = img_clf.load_data_from_folder('test/')\n","print()\n","\n","# convert images into features, example using hog features\n","print('Extracting HOG features...')\n","# train_data_hog = img_clf.extract_image_features(train_raw, feature.hog)\n","# test_data_hog = img_clf.extract_image_features(test_raw, feature.hog)\n","\n","# repeat with at least one other feature type..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QHW9Rr1O5peP"},"source":["# Inspecting the features.\n","print('HOG Feature Vector')\n","print(train_data_hog[0])\n","print(f'Vector Size: {len(train_data_hog[0])}')\n","print()\n","\n","print('##########################################################################')\n","print()\n","\n","# repeat with at least one other feature type..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Co_et4A-58X5"},"source":["## Step 3: Implement classifier training and testing\n","Next, implement the `train_classifier` and `predict_labels` functions for at least two different types of classifiers. After this, the second cell below shoul then produce performance results of the classifier.\n","\n","Explore the performance of at least **two feature types** and at least **two classifiers** (i.e. at least four different combinations) in terms of classification **performance** on the test set. Update the code to display the **F1 score** on the test set for the **four different combinations** with informative prompts. Then the code should display the **detailed performance** (confusion matrix, accuracy, F1 score) that is already displayed only for the best performing combination of features and classifier. Also make sure the best performing classifier is saved onto your drive for the next step of the lab."]},{"cell_type":"code","metadata":{"id":"XHzU_eUg5K7V"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","# Continue implementation of the ImageClassifier class in this cell\n","class ImageClassifier(ImageClassifier):\n","\n","    def train_classifier(self, train_data, train_labels, classifier=KNeighborsClassifier):\n","        \n","        self.classifier = classifier()\n","        self.classifier.fit(train_data, train_labels)\n","\n","\n","    def predict_labels(self, data):\n","        \n","        predicted_labels = self.classifier.predict(data)\n","        \n","        return predicted_labels        \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qzu432Q86AMR"},"source":["Re-run initialization and feature extraction, then train/test the classifier."]},{"cell_type":"code","metadata":{"id":"44IFo86c6J-G"},"source":["img_clf = ImageClassifier()\n","\n","# create list of list containing features you want to run through along with any\n","# associated metadata\n","\n","# features = \n","\n","# create list of list of classifiers you want to use \n","\n","# classifiers = \n","\n","# Variable to hold the best F1 score\n","best_f1 = 0\n","\n","# Loop through the different combinantions of features and classifiers\n","for feature in features:\n","  for classifier in classifiers:  \n","    \n","    # Train model \n","\n","    # Test model\n","    \n","    # Create confusion matrix\n","\n","    # Print test accuracy\n","\n","    # Print test F1 score\n","    \n","    # Check if last model is better than the current best one and save it\n","    \n","    pass # delete this line"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MF_Qu0I9O0zl"},"source":["## Step 4: Transfer classifier to your camera\n","\n","Next you will apply your trained classifier directly onto images captured by your webcam. Since this is our last lab using Python we would like to give you the opportunity to install Python and Jupyter notebooks on your machine, and do this part of the lab as a conventional Python script. However, if you would rather not do that at the moment, you still have the option of doing this part with Colab Notebooks.\n","\n","* **Option 1:** If you would like to do this part locally, first follow the Python Installation guidelines. Then download the skeleton camera capture script `camera.py` and test it out. Then update this script as described below and submit this script. Make sure you note in lab4.ipynb that you chose this option.\n","* **Option 2:** If you would like to do this part in Colab Notebooks, add your code below. Check out [`camera.ipynb`](https://colab.research.google.com/drive/1IfHqK83dDVyxsQzQwsnxc4CUrRUoL9y8) for sample code for capturing camera images in Colab notebooks.\n","\n","Your code should first load the classifier you saved in Step 3 with the following line (already implemented in the sample code):\n","\n","`classifier = joblib.load('classifier.joblib')`\n","\n","The script should then go into a loop where it (1) captures a new image from the camera, (2) processes the image to make it grayscale and filter the noise, (3) extracts the features like you did in Step 2 using the right set of features for your trained classifier, (4) detects whether the image contains one of the seven images using the trained classifier, and (5) displays the detected class name on the image in every iteration. You can use the images printed on paper provided by the TAs to test your script with your camera."]},{"cell_type":"code","metadata":{"id":"JxAIUMPmPRY-"},"source":["from IPython.display import HTML, Audio\n","from IPython.display import clear_output\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","import io as io2\n","from PIL import Image\n","import time\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","import cv2\n","\n","from skimage.color import rgb2gray\n","\n","############################\n","####### CAMERA CODE ########\n","############################\n","\n","VIDEO_HTML = \"\"\"\n","<video autoplay\n"," width=%d height=%d style='cursor: pointer;'></video>\n","<script>\n","\n","var video = document.querySelector('video')\n","\n","navigator.mediaDevices.getUserMedia({ video: true })\n","  .then(stream=> video.srcObject = stream)\n","\n","function getFrame() {\n","    var canvas = document.createElement('canvas')\n","    var [w,h] = [video.offsetWidth, video.offsetHeight]\n","    canvas.width = w\n","    canvas.height = h\n","    canvas.getContext('2d')\n","          .drawImage(video, 0, 0, w, h)\n","    return canvas.toDataURL('image/jpeg', 0.8)\n","}\n","\n","</script>\n","\"\"\"\n","\n","# Make sure the pictures taken by your camera match the size of the \n","# training set â€“ 320px x 240px\n","def start_camera(filename='photo.jpg', quality=0.8, size=(320,240)):\n","  display(HTML(VIDEO_HTML % (size[0],size[1])))\n","\n","def take_photo(filename='photo.jpg', quality=0.8, size=(320,240)):\n","  data = eval_js('getFrame()')\n","  binary = b64decode(data.split(',')[1])\n","  f = io2.BytesIO(binary)\n","  return np.asarray(Image.open(f))\n","\n","############################\n","############################\n","############################\n","\n","class ImageClassifier(ImageClassifier):\n","  \n","  def load_classifier(self):\n","    print('Loading classifier...')\n","    self.classifier = joblib.load(self.folder + 'classifier.joblib')\n","\n","# Create a new instance of the classifier\n","img_clf = ImageClassifier()\n","\n","# Load the previously saved model\n","img_clf.load_classifier()\n","\n","# Start camera and wait for it to \"warm up\"\n","start_camera()\n","time.sleep(3)\n","\n","while(True):\n","  img = take_photo() # click\n","\n","  ##############################################################################\n","  ############################ YOUR CODE HERE ##################################\n","  ##############################################################################\n","\n","  # Convert to grayscale\n","\n","  # Extract features from the image just caputred\n","  \n","  # Show frame and prediction\n","  \n","  time.sleep(1)\n","\n","  break # delete this line\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1hRob3q_Qedo"},"source":["## (Optional) Improve classifier\n","\n","You will notice that your classifier is prone to errors when tested with your camera. Part of the reason is that the images were collected from a different camera. You can try improving the performance of your camera image classifier by re-training your classifier with images collected from your camera."]},{"cell_type":"markdown","metadata":{"id":"rxJ9SZubQjKl"},"source":["## Step 5: Submit your code on Canvas\n","\n","Complete this lab by submitting a link to your updated Colab Notebook (and if you chose Option 1 in Step 4, by uploading your updated `camera.py`) on Canvas, by Oct 22 Tuesday, 11:59pm. We will test your code by running it and inspecting the classification results to make sure: \n","* A comparison of  at least four combinations of feature types and classifiers were made\n","* A reasonable classification performance was achieved with the best combination (higher than random chance).\n","\n","We will test your camera image classification code by running it and showing it the seven different printed images to check that more than half of the images can be recognized correctly in some configuration relative to the camera.\n","\n","See Canvas for a grading rubric."]}]}